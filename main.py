import streamlit as st
import os
import time
from time import sleep
from pathlib import Path
from streamlit.components.v1 import html
from langchain.memory import ConversationSummaryBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder,
)
from langchain.schema import SystemMessage
from openai import OpenAI
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import functions as ft
import constants as ct
import uuid
from initialize import initialize
from state_manager import reset_conversation


# å„ç¨®è¨­å®š
load_dotenv()
st.set_page_config(
    page_title=ct.APP_NAME
)

# ã‚¿ã‚¤ãƒˆãƒ«è¡¨ç¤º
st.markdown(f"## {ct.APP_NAME}")

# åˆæœŸåŒ–å‡¦ç†
initialize()


# ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã®ä¸€è¦§è¡¨ç¤º
if st.session_state.start_flg:
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            with st.chat_message(message["role"], avatar="images/ai_icon.jpg"):
                st.markdown(message["content"])
        elif message["role"] == "user":
            with st.chat_message(message["role"], avatar="images/user_icon.jpg"):
                st.markdown(message["content"])
        else:
            st.divider()

# ä¼šè©±é–‹å§‹ãƒœã‚¿ãƒ³ã¨ä¸­æ–­ãƒœã‚¿ãƒ³ã®åˆ‡ã‚Šæ›¿ãˆ
if st.session_state.start_flg:
    if st.button("ä¸­æ–­", use_container_width=True):
        reset_conversation()
        st.session_state.start_flg = False
        st.rerun()
else:
    if st.button("é–‹å§‹", use_container_width=True, type="primary"):
        reset_conversation()
        st.session_state.start_flg = True
        st.session_state.show_reset_message = False
        st.rerun()

# ä¼šè©±æœªé–‹å§‹ã®å ´åˆã¯ä»¥é™ã®å‡¦ç†ã‚’åœæ­¢
if not st.session_state.start_flg:
    st.stop()

# LLMãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ä¸‹éƒ¨ã«ãƒ¢ãƒ¼ãƒ‰å®Ÿè¡Œã®ãƒœã‚¿ãƒ³è¡¨ç¤º
if st.session_state.start_flg:
    if st.session_state.shadowing_flg:
        st.session_state.shadowing_button_flg = st.button("ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°é–‹å§‹")
    if st.session_state.dictation_flg:
        st.session_state.dictation_button_flg = st.button("ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹")

# ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ¢ãƒ¼ãƒ‰ã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å—ä»˜æ™‚ã«å®Ÿè¡Œ
if st.session_state.chat_open_flg:
    st.info("AIãŒèª­ã¿ä¸Šã’ãŸéŸ³å£°ã‚’ã€ç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰ãã®ã¾ã¾å…¥åŠ›ãƒ»é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")

# ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰æ™‚ã®ã¿ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚’è¡¨ç¤º
if st.session_state.mode == ct.MODE_3:
    st.session_state.dictation_chat_message = st.chat_input("AIã®éŸ³å£°ã‚’èã„ã¦ã€è‹±æ–‡ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
else:
    st.session_state.dictation_chat_message = ""

if st.session_state.dictation_chat_message and not st.session_state.chat_open_flg:
    st.stop()

# ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
if st.session_state.start_flg:

    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€
    # ã€Œãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ãƒãƒ£ãƒƒãƒˆé€ä¿¡æ™‚
    if st.session_state.mode == ct.MODE_3 and (st.session_state.dictation_button_flg or st.session_state.dictation_count == 0 or st.session_state.dictation_chat_message):
        if st.session_state.dictation_first_flg:
            system_template_with_level = ct.SYSTEM_TEMPLATE_CREATE_PROBLEM.format(level=st.session_state.englv)
            st.session_state.chain_create_problem = ft.create_chain(system_template_with_level)
            st.session_state.dictation_first_flg = False
        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ä»¥å¤–
        if not st.session_state.chat_open_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                try:
                    st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio()
                    if not st.session_state.problem:
                        st.error("å•é¡Œæ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                        st.stop()

                    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”Ÿæˆ
                    audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
                    ft.save_to_wav(llm_response_audio.content, audio_output_file_path)

                    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤ºï¼ˆå†ç”Ÿãƒœã‚¿ãƒ³ä»˜ãï¼‰
                    st.audio(audio_output_file_path)

                    # ãƒ‡ã‚£ã‚¯ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å›ç­”å¾…ã¡ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
                    st.info("AIãŒèª­ã¿ä¸Šã’ãŸéŸ³å£°ã‚’ã€ç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰ãã®ã¾ã¾å…¥åŠ›ãƒ»é€ä¿¡ã—ã¦ãã ã•ã„ã€‚")
                    st.session_state.chat_open_flg = True

                except Exception as e:
                    st.error(f"å•é¡Œæ–‡ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    st.stop()

        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ™‚ã®å‡¦ç†
        else:
            # ãƒãƒ£ãƒƒãƒˆæ¬„ã‹ã‚‰å…¥åŠ›ã•ã‚ŒãŸå ´åˆã«ã®ã¿è©•ä¾¡å‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
            if not st.session_state.dictation_chat_message:
                st.stop()
            
            # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(st.session_state.problem)
            with st.chat_message("user", avatar=ct.USER_ICON_PATH):
                st.markdown(st.session_state.dictation_chat_message)

            # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨ãƒãƒ£ãƒƒãƒˆå…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
            st.session_state.messages.append({"role": "user", "content": st.session_state.dictation_chat_message})
            
            with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
                system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                    llm_text=st.session_state.problem,
                    user_text=st.session_state.dictation_chat_message,
                    level=st.session_state.englv
                )
                st.session_state.chain_evaluation = ft.create_chain(system_template)
                # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆã‚’æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
                llm_response_evaluation = ft.create_evaluation()
            
            # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(llm_response_evaluation)
            st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
            st.session_state.messages.append({"role": "other"})
            
            # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
            st.session_state.dictation_flg = True
            st.session_state.dictation_chat_message = ""
            st.session_state.dictation_count += 1
            st.session_state.chat_open_flg = False

            st.rerun()

    
    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œæ—¥å¸¸è‹±ä¼šè©±ã€
    if st.session_state.mode == ct.MODE_1:
        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        try:
            ft.record_audio(audio_input_file_path)
        except Exception as e:
            st.error(f"éŸ³å£°ã®éŒ²éŸ³ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.stop()

        # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            transcript, warning_message = ft.transcribe_audio(audio_input_file_path)
            audio_input_text = transcript.text
            
            # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚Œã°è¡¨ç¤º
            if warning_message:
                st.warning(warning_message)

        # éŸ³å£°å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®ç”»é¢è¡¨ç¤º
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(audio_input_text)
        
        with st.spinner("å›ç­”ã®éŸ³å£°èª­ã¿ä¸Šã’æº–å‚™ä¸­..."):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’LLMã«æ¸¡ã—ã¦å›ç­”å–å¾—
            llm_response = st.session_state.chain_basic_conversation.predict(input=audio_input_text)
            
            # LLMã‹ã‚‰ã®å›ç­”ã‚’éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›
            llm_response_audio = st.session_state.openai_obj.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input=llm_response
            )

            # ä¸€æ—¦mp3å½¢å¼ã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¾Œã€wavå½¢å¼ã«å¤‰æ›
            audio_output_file_path = f"{ct.AUDIO_OUTPUT_DIR}/audio_output_{int(time.time())}.wav"
            ft.save_to_wav(llm_response_audio.content, audio_output_file_path)

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿ä¸Šã’
        # ft.play_wav(audio_output_file_path, speed=st.session_state.speed)
        # play_wav é–¢æ•°ã¯å¤‰æ›´ã•ã‚ŒãŸãŸã‚ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
        # ft.play_wav(audio_output_file_path, speed=st.session_state.speed)

        # ä»£ã‚ã‚Šã« change_speed ã‚’ä½¿ç”¨
        if st.session_state.speed != 1.0:
            temp_audio_path = f"{ct.AUDIO_OUTPUT_DIR}/temp_{uuid.uuid4().hex}.wav"
            ft.change_speed(audio_output_file_path, temp_audio_path, st.session_state.speed)
        else:
            temp_audio_path = audio_output_file_path

        st.session_state.temp_audio_path = temp_audio_path
        st.audio(temp_audio_path)

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤ºã¨ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ 
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã®æ·»å‰Šï¼ˆONæ™‚ã®ã¿ï¼‰
            if st.session_state.show_corrections:
                with st.spinner('æ·»å‰Šä¸­...'):
                    correction = ft.correct_user_input(audio_input_text, st.session_state.englv)
                
                if correction:
                    with st.expander("ğŸ“ ã‚ãªãŸã®ç™ºè©±ã‚’ã‚ˆã‚Šè‰¯ãã™ã‚‹ã«ã¯"):
                        st.markdown(correction)
            
            # AIè¿”äº‹ã®æ—¥æœ¬èªè¨³ï¼ˆONæ™‚ã®ã¿ï¼‰
            if st.session_state.show_translation:
                with st.spinner('ç¿»è¨³ä¸­...'):
                    translation = ft.translate_to_japanese(llm_response)
                
                if translation:
                    with st.expander("ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªè¨³ã‚’è¦‹ã‚‹"):
                        st.markdown(translation)

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã¨LLMã‹ã‚‰ã®å›ç­”ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¸€è¦§ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": audio_input_text})
        st.session_state.messages.append({"role": "assistant", "content": llm_response})


    # ãƒ¢ãƒ¼ãƒ‰ï¼šã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€
    # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã‹ã€ã€Œè‹±ä¼šè©±é–‹å§‹ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚
    if st.session_state.mode == ct.MODE_2 and (st.session_state.shadowing_button_flg or st.session_state.shadowing_count == 0 or st.session_state.shadowing_audio_input_flg):
        if st.session_state.shadowing_first_flg:
            system_template_with_level = ct.SYSTEM_TEMPLATE_CREATE_PROBLEM.format(level=st.session_state.englv)
            st.session_state.chain_create_problem = ft.create_chain(system_template_with_level)
            st.session_state.shadowing_first_flg = False
        
        if not st.session_state.shadowing_audio_input_flg:
            with st.spinner('å•é¡Œæ–‡ç”Ÿæˆä¸­...'):
                try:
                    st.session_state.problem, llm_response_audio = ft.create_problem_and_play_audio()
                    if not st.session_state.problem:
                        st.error("å•é¡Œæ–‡ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                        st.stop()
                except Exception as e:
                    st.error(f"å•é¡Œæ–‡ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    st.stop()

            # å•é¡Œæ–‡ã‚’è¡¨ç¤º
            with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
                st.markdown(st.session_state.problem)

        # éŸ³å£°å…¥åŠ›ã‚’å—ã‘å–ã£ã¦éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        st.session_state.shadowing_audio_input_flg = True
        audio_input_file_path = f"{ct.AUDIO_INPUT_DIR}/audio_input_{int(time.time())}.wav"
        try:
            ft.record_audio(audio_input_file_path)
        except Exception as e:
            st.error(f"éŸ³å£°ã®éŒ²éŸ³ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.stop()
            
        st.session_state.shadowing_audio_input_flg = False

        with st.spinner('éŸ³å£°å…¥åŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...'):
            # éŸ³å£°å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            transcript, warning_message = ft.transcribe_audio(audio_input_file_path)
            audio_input_text = transcript.text
            
            # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã‚ã‚Œã°è¡¨ç¤º
            if warning_message:
                st.warning(warning_message)

        # AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ç”»é¢è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(st.session_state.problem)
        with st.chat_message("user", avatar=ct.USER_ICON_PATH):
            st.markdown(audio_input_text)
        
        # LLMãŒç”Ÿæˆã—ãŸå•é¡Œæ–‡ã¨éŸ³å£°å…¥åŠ›å€¤ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã«è¿½åŠ 
        st.session_state.messages.append({"role": "assistant", "content": st.session_state.problem})
        st.session_state.messages.append({"role": "user", "content": audio_input_text})

        with st.spinner('è©•ä¾¡çµæœã®ç”Ÿæˆä¸­...'):
            if st.session_state.shadowing_evaluation_first_flg:
                system_template = ct.SYSTEM_TEMPLATE_EVALUATION.format(
                    llm_text=st.session_state.problem,
                    user_text=audio_input_text,
                    level=st.session_state.englv
                )
                st.session_state.chain_evaluation = ft.create_chain(system_template)
                st.session_state.shadowing_evaluation_first_flg = False
            # å•é¡Œæ–‡ã¨å›ç­”ã‚’æ¯”è¼ƒã—ã€è©•ä¾¡çµæœã®ç”Ÿæˆã‚’æŒ‡ç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
            llm_response_evaluation = ft.create_evaluation()
        
        # è©•ä¾¡çµæœã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã¸ã®è¿½åŠ ã¨è¡¨ç¤º
        with st.chat_message("assistant", avatar=ct.AI_ICON_PATH):
            st.markdown(llm_response_evaluation)
        st.session_state.messages.append({"role": "assistant", "content": llm_response_evaluation})
        st.session_state.messages.append({"role": "other"})
        
        # å„ç¨®ãƒ•ãƒ©ã‚°ã®æ›´æ–°
        st.session_state.shadowing_flg = True
        st.session_state.shadowing_count += 1

        # ã€Œã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ã€ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«å†æç”»
        st.rerun()